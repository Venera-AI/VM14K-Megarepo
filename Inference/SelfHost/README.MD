# Script to run evaluation on your server with vLLM
## Notes:

- Add/Remove model in `run.py`
- Change vLLM config in `run_nonreasoning.py` and `run_reasoning.py`
- The `run_reasoning.py` script handle R1-Distill-Llama-8B and HuatuoGPT-o1 different from the others


## How to run

1. Install vLLM
1. Run `run.py`
